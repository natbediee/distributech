# Distributech

## ğŸ“‘ Sommaire
- [ğŸ“– PrÃ©sentation](#-prÃ©sentation)
- [ğŸ“‚ Sources de donnÃ©es](#-sources-de-donnÃ©es)
- [ğŸ› ï¸ Pipeline ETL](#ï¸-pipeline-etl)
- [ğŸ—„ï¸ Base relationnelle](#ï¸-base-relationnelle)
- [ğŸ“Š Tabeau de Bord](#-tableau-de-bord)
- [ğŸ—ï¸ Architecture du projet](#-architecture-du-projet)
- [ğŸš€ Installation](#-installation)
- [ğŸ“‚ Arborescence du projet](#-arborescence-du-projet)
- [â–¶ï¸ Utilisation](#ï¸-utilisation)
- [ğŸ“‘ Documentations](#-documentations)
- [ğŸ“Œ Auteur](#-auteur)

## ğŸ“– PrÃ©sentation
Projet pÃ©dagogique consistant Ã  mettre en place un processus **ETL en Python** pour centraliser les donnÃ©es de commandes et de stocks de lâ€™entreprise fictive *Distributech*, grossiste en Ã©quipements Ã©lectroniques.

## ğŸ“‚ Sources de donnÃ©es
- **Fichiers CSV hebdomadaires** : commandes envoyÃ©es par les revendeurs.
- Exemple fichier `commandes_revendeur.csv` :
  ```csv
  numero_commande,commande_date,revendeur_id,region_id,product_id,quantity,unit_price
  CMD-20250710-001,2025-07-10,1,1,101,5,59.9
  CMD-20250710-001,2025-07-10,1,1,102,10,19.9
- **Base SQLite locale** : rÃ©fÃ©rentiels (produits, rÃ©gions, revendeurs) et mouvements de production(production).  

## ğŸ› ï¸ Pipeline ETL
- **Extract** : lecture des fichiers CSV et de la base SQLite.  
- **Transform** : nettoyage, normalisation, suppression des doublons, gestion des incohÃ©rences.  
- **Load** : intÃ©gration dans la base relationnelle MySQL.  

Un export CSV de lâ€™Ã©tat du stock est produit en fin de cycle.

## ğŸ—„ï¸ Base relationnelle
La base MySQL cible est organisÃ©e autour des tables :  
`regions`, `revendeurs`, `produits`, `commandes`, `lignes_cmd`, `production`.  

Trois vues principales facilitent lâ€™analyse :  
- `v_stock` â†’ Ã©tat courant du stock  
- `v_cmds_par_region` â†’ commandes par rÃ©gion  
- `v_chiffre_affaires_par_region` â†’ chiffre dâ€™affaires consolidÃ©  

## ğŸ“Š Tableau de bord
Il permet dâ€™interroger directement la base, de consulter les indicateurs :
- Suivi des stocks globaux et par produit
- Historique des commandes  
- Chiffre dâ€™affaires par rÃ©gion  
- Export CSV possible des rÃ©sultats

## ğŸ—ï¸ Architecture du projet
Le schÃ©ma ci-dessous illustre lâ€™organisation gÃ©nÃ©rale du pipeline ETL et des flux de donnÃ©es :
```mermaid
flowchart TD
  subgraph Sources
    A1[CSV Commandes]
    A2[Base SQLite<br>rÃ©fÃ©rentiels<br>+ production]
  end

  A1 --> B[ETL<br>Extract â‡’ Transform â‡’ Load]
  A2 --> B

  B --> C[Base de donnÃ©es cible]
  B -.-> L[Journal des logs]
  C --> D1[Stock en Export CSV]
  C --> D2[Tableau de Bord de consultation]
```

## ğŸ’» Technologies utilisÃ©es

- **Langage** : Python 3.x  
- **BibliothÃ¨ques principales** :  
  - pandas â†’ traitement et transformation des donnÃ©es  
  - mysql.connector â†’ connexion et requÃªtes MySQL  
  - sqlite3 â†’ lecture de la base SQLite locale  
- **Base relationnelle cible** : MySQL  
- **CompatibilitÃ© OS** : Windows et Linux  
- **ExÃ©cution** : mode batch (pipeline complet sans interaction utilisateur)  

## ğŸš€ Installation
**1. Cloner le projet et prÃ©parer lâ€™environnement Python**
```bash
git clone https://github.com/natbediee/distributech.git
cd distributech
python3 -m venv .dtvenv
source .dtvenv/bin/activate
pip install -r requirements.txt
```
**2. Configurer les variables dâ€™environnement**

Copier le modÃ¨le .env.template et complÃ©ter vos informations :
```bash
cp .env.template .env
```
**3. Lancer lâ€™infrastructure MySQL (Docker)**
```bash
docker compose -f bdd/docker-compose.yml up -d
```

MySQL : localhost:3306

Adminer : http://localhost:8080

**4. CrÃ©er la base SQLite locale**
```bash
python3 scripts/db_stock.py
```

Cette base contient les rÃ©fÃ©rentiels (produits, rÃ©gions, revendeurs) et les mouvements de production(produciton).

## ğŸ“‚ Arborescence du projet
```
.
â”œâ”€â”€ scripts/               
â”‚   â”œâ”€â”€ main_etl.py        # Pilotage global du processus ETL
â”‚   â”œâ”€â”€ db_sql.py          # CrÃ©ation de la base MySQL (si absente)
â”‚   â”œâ”€â”€ db_stock.py        # CrÃ©ation de la base SQLite locale
â”‚   â”œâ”€â”€ extract.py         # Extraction des donnÃ©es depuis CSV et SQLite
â”‚   â”œâ”€â”€ transform.py       # Nettoyage et validation des donnÃ©es
â”‚   â”œâ”€â”€ load.py            # Chargement dans la base centrale
â”‚   â”œâ”€â”€ post_etl.py        # GÃ©nÃ©ration de lâ€™Ã©tat des stocks aprÃ¨s ETL
â”‚   â”œâ”€â”€ query_menu.py      # Tableau de bord SQL en ligne de commande
â”‚   â””â”€â”€ commun.py          # Fonctions partagÃ©es (logs, vÃ©rificationsâ€¦)
â”‚
â”œâ”€â”€ data/                  
â”‚   â”œâ”€â”€ in/                # Fichiers CSV dâ€™entrÃ©e
â”‚   â”œâ”€â”€ log/               # Logs ETL
â”‚   â”œâ”€â”€ stock/             # Exports de stock gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€ treated/           # Fichiers CSV traitÃ©s
â”‚
â”œâ”€â”€ docs/                  
â”‚   â”œâ”€â”€ CDC_Distributech_nbediee.pdf
â”‚   â”œâ”€â”€ DT_Distributech_nbediee.pdf
â”‚   â””â”€â”€ Distributech_Gantt_nbediee.pdf
â”‚
â”œâ”€â”€ bdd/
â”‚   â””â”€â”€ docker-compose.yml # Services MySQL + Adminer
â”‚
â”œâ”€â”€ requirements.txt       
â”œâ”€â”€ README.md              
â”œâ”€â”€ .gitignore             
â”œâ”€â”€ .env.example           
â””â”€â”€ .env                   # Variables locales (non versionnÃ©)
```
## â–¶ï¸ Utilisation

Lancer lâ€™ETL complet :
```bash
python3 scripts/main_etl.py
```

Consulter les rÃ©sultats dans  :

Exports CSV gÃ©nÃ©rÃ©s dans data/stock/

Pour lancer le Tableau de bord interactif :
```bash
python3 scripts/query_menu.py
```

## ğŸ“‘ Documentations

- Cahier des charges

- Dossier technique

- Planning Gantt

## ğŸ“Œ Auteur

Projet rÃ©alisÃ© par **Nathalie Bediee** dans le cadre de la formation **DÃ©veloppeur IA â€“ ISEN Brest**.

ğŸ”— [Mon profil LinkedIn](https://www.linkedin.com/in/nathalie-b%C3%A9di%C3%A9e-548652295/)
